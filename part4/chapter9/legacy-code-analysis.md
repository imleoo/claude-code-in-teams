# 遗留代码的智能考古与文档生成

重构项目的第一个拦路虎，往往不是技术难题，而是“看不懂”。面对成千上万行没有文档、逻辑混乱、由已离职员工编写的“祖传代码”，任何团队都会感到头痛。这个过程，我们称之为“代码考古”。传统的代码考古耗时、枯燥且极易出错。

但在“团队Vibe Coding”模式下，我们有了一位不知疲倦、智力超群的“考古专家”——AI。

## 核心理念：让AI读代码，人读文档

我们的策略很简单：将最繁重、最琐碎的代码阅读工作交给AI，让人类开发者专注于理解AI提炼出的业务逻辑和架构，从而做出正确的重构决策。

这个过程分为三步：**代码切片 -> AI分析 -> 文档合成**。

### 第一步：代码切片与优先级排序

我们不能把整个旧代码库一次性丢给AI。后端工程师张伟和数据工程师（暂定为赵四）首先对旧的PHP代码库进行“切片”和优先级排序。

1.  **识别入口点**：找到处理前端请求的核心PHP文件，如 `api/get_summary.php`, `data/get_gmv_trend.php` 等。
2.  **分析复杂度**：使用简单的命令行工具（如`cloc`或`wc -l`）结合`git log`，找出代码行数最多、历史修改最频繁的文件。这些通常是逻辑最复杂、业务价值最高的地方。
3.  **分类**：将文件分为三类：
    - **纯业务逻辑**：包含大量`if/else`和计算。
    - **数据查询密集型**：包含大量、复杂的SQL拼接。
    - **配置与工具类**：如数据库连接、日期格式化等。

### 第二步：AI驱动的代码到文档转换

这是“智能考古”的核心环节。团队利用AI，针对不同类型的代码切片进行“定向爆破”。

#### 场景一：解释复杂的业务逻辑

张伟发现一个名为 `calculate_user_level.php` 的文件，里面有几百行业务逻辑。

**张伟的Prompt:**
> 你是一位资深的PHP开发专家。请阅读并解释以下PHP文件的作用。
>
> ```php
> // (粘贴 calculate_user_level.php 的全部内容)
> ```
>
> 请以Markdown格式输出你的分析，包含以下部分：
> 1.  **文件功能概述**：这个文件是做什么的？
> 2.  **核心逻辑拆解**：请按步骤描述用户等级的计算逻辑。
> 3.  **输入与输出**：该脚本依赖哪些全局变量或数据库表？它最终会输出或影响什么？
> 4.  **潜在问题**：代码中是否存在任何不明确的、可能存在风险的逻辑？

AI的输出清晰地指出了用户等级是根据“最近30天消费金额”、“登录频率”和“是否为付费会员”三个维度加权计算的，并点出了其中一个`if`判断条件存在逻辑漏洞。

#### 场景二：翻译天书般的SQL查询

数据工程师赵四在 `data/get_gmv_trend.php` 中发现了一段长达50行的、通过字符串拼接而成的SQL查询。

**赵四的Prompt:**
> 你是一位SQL性能优化专家。请分析下面这段从PHP代码中提取的MySQL查询。
>
> ```sql
> // (粘贴拼接后的SQL查询字符串)
> ```
>
> 请回答：
> 1.  **查询意图**：这个查询想统计什么业务指标？
> 2.  **性能瓶颈**：分析这个查询的执行计划，找出主要的性能瓶颈（如：全表扫描、未使用索引、笛卡尔积等）。
> 3.  **重写建议**：请用更清晰、更高性能的方式重写这个查询。

AI不仅解释了该查询是在计算“分渠道的日均GMV”，还明确指出了其`JOIN`条件不当导致了全表扫描，并给出了一个使用`WITH`子句和窗口函数重构的、性能更优的版本。

### 第三步：文档合成与知识沉淀

AI生成的分析是“原材料”，团队需要将其加工成系统化的、持久化的新项目文档。

1.  **生成API文档**：基于AI对旧接口文件的分析，团队快速编写出了新系统的OpenAPI规范，明确了每个接口的请求、响应和业务逻辑。
2.  **绘制架构图**：利用AI分析出的数据流和模块依赖关系，团队使用Mermaid图绘制了旧系统的真实架构图和数据流转图，这对于理解系统全貌至关重要。
3.  **建立数据字典**：AI帮助团队解析了所有SQL查询，识别出了所有用到的数据库表和字段，并推断出每个字段的业务含义，从而快速建立起新项目的数据字典。

---

**本节小结：** 面对遗留代码，AI考古不是简单的“代码翻译”，而是一个**集阅读、分析、诊断、建议于一体**的智能化过程。它将开发者从“猜”和“试”的泥潭中解放出来，极大地缩短了项目启动阶段的认知负载和时间成本。通过这个过程，我们不仅“复活”了丢失的文档，还提前发现了旧系统的设计缺陷和性能瓶颈，为后续的重构工作铺平了道路，并提供了明确的优化方向。

**下一节：** [AI辅助的数据迁移策略与验证](data-migration.md)